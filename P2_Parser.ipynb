{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDUO2M1T5ytJ"
      },
      "source": [
        "## Escrevendo um Analisador Sintático para a Linguagem uChuck"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JA0bHwhh6dsU"
      },
      "source": [
        "Nesta etapa, você deve escrever uma versão preliminar de um analisador sintático para a linguagem uChuck. A especificação da gramática do uChuck em BNF está [aqui](https://colab.research.google.com/drive/1GiV8weG5lzVvA7z970EiE8bUMj3DAg0x?usp=sharing). Sua tarefa é escrever regras de análise sintática usando o SLY. Para um melhor entendimento, estude o capítulo [“Escrevendo um Analisador Sintático”](https://sly.readthedocs.io/en/latest/sly.html#writing-a-parser)\n",
        "da documentação do SLY."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RULWDcsc8xL3"
      },
      "source": [
        "### Especificação\n",
        "Sua tarefa é traduzir as regras listadas em uma gramática BNF em uma coleção de métodos decorados pelo decorador `@_()`. O nome de cada método deve corresponder ao nome da regra gramatical que está sendo analisada. O argumento para o decorador `@_()` é uma cadeia de caracteres que descreve o lado direito da gramática. Assim, uma regra gramatical como:\n",
        "\n",
        "```\n",
        "    <program> ::= <statement_list> EOF\n",
        "```\n",
        "\n",
        "torna-se um método de classe do Python da forma:\n",
        "\n",
        "```python\n",
        "class UChuckParser(Parser):\n",
        "    \"\"\"A parser for the uChuck language.\"\"\"\n",
        "    ...\n",
        "    # <program> ::= <statement_list> EOF\n",
        "    @_('statement_list')\n",
        "    def program(self, p):\n",
        "        return ('program', p.statement_list)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7yKZtXt-VYa"
      },
      "source": [
        "Para construir uma árvore de sintaxe, basta criar e retornar uma tupla ou lista em cada função de regra gramatical, como mostrado acima."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9clEvFodDHna"
      },
      "source": [
        "Seu objetivo, ao final deste segundo projeto, é reconhecer **sintaticamente** programas expressos na linguagem uChuck.\n",
        "Para isso, o ideal é que você faça com que sua gramática não apresente **nenhum** conflito empilha/reduz."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qg78lzrlD5Ia"
      },
      "source": [
        "**Sugestão:** Você deve começar de forma simples e trabalhar incrementalmente até construir a gramática completa."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5s2-Br3sekZ"
      },
      "source": [
        "### Esboço do Analisador Sintático"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2od-Z5Bav9vq"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sly in c:\\users\\leope\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.5)\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "!pip install sly\n",
        "from sly import Lexer, Parser"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4i4Y0LaL4Mo4"
      },
      "source": [
        "Copie o código da classe `UChuckLexer` que você escreveu no [primeiro projeto](https://colab.research.google.com/drive/1FXsbf3mp9rf-Cce-c9qk_8S43ppcPd4k?usp=sharing) e cole na célula abaixo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "k29n4mDJwHj5"
      },
      "outputs": [],
      "source": [
        "class UChuckLexer(Lexer):\n",
        "    \"\"\"A lexer for the uChuck language.\"\"\"\n",
        "\n",
        "    def __init__(self, error_func):\n",
        "        \"\"\"Create a new Lexer.\n",
        "        An error function. Will be called with an error\n",
        "        message, line and column as arguments, in case of\n",
        "        an error during lexing.\n",
        "        \"\"\"\n",
        "        self.error_func = error_func\n",
        "\n",
        "    # Reserved keywords\n",
        "    keywords = {\n",
        "        'int': \"INT\",\n",
        "        'float': \"FLOAT\",\n",
        "        'if': \"IF\",\n",
        "        'else': \"ELSE\",\n",
        "        'while': \"WHILE\",\n",
        "        'break': \"BREAK\",\n",
        "        'continue': \"CONTINUE\",\n",
        "        'true': \"TRUE\",\n",
        "        'false': \"FALSE\",\n",
        "    }\n",
        "\n",
        "    # All the tokens recognized by the lexer\n",
        "    tokens = tuple(keywords.values()) + (\n",
        "        # Identifiers\n",
        "        \"ID\",\n",
        "        # Constants\n",
        "        \"FLOAT_VAL\",\n",
        "        \"INT_VAL\",\n",
        "        \"STRING_LIT\",\n",
        "        # Operators\n",
        "        \"PLUS\",\n",
        "        \"MINUS\",\n",
        "        \"TIMES\",\n",
        "        \"DIVIDE\",\n",
        "        \"PERCENT\",\n",
        "        \"LE\",\n",
        "        \"LT\",\n",
        "        \"GE\",\n",
        "        \"GT\",\n",
        "        \"EQ\",\n",
        "        \"NEQ\",\n",
        "        \"AND\",\n",
        "        \"OR\",\n",
        "        \"EXCLAMATION\",\n",
        "        # Assignment\n",
        "        \"CHUCK\",\n",
        "        # Delimeters\n",
        "        \"LPAREN\",\n",
        "        \"RPAREN\",  # ( )\n",
        "        \"LBRACE\",\n",
        "        \"RBRACE\",  # { }\n",
        "        \"L_HACK\",\n",
        "        \"R_HACK\",  # <<< >>>\n",
        "        \"COMMA\",\n",
        "        \"SEMI\",  # , ;\n",
        "    )\n",
        "\n",
        "    # String containing ignored characters (between tokens)\n",
        "    ignore = \" \\t\"\n",
        "\n",
        "    # Other ignored patterns\n",
        "    ignore_newline = r'\\n+'\n",
        "    ignore_comment = r'/\\*(.|\\n)*?\\*/|//.*'\n",
        "\n",
        "    # Regular expression rules for tokens\n",
        "    ID = r'[a-zA-Z_][a-zA-Z0-9_]*'\n",
        "    FLOAT_VAL = r'\\d+\\.\\d+|\\d+\\.\\d*|\\.\\d+'\n",
        "    INT_VAL = r'\\d+'\n",
        "    STRING_LIT = r'\"([^\"\\\\]|\\\\.)*\"'\n",
        "    \n",
        "    unterm_string = r'\"(\\\\[\"\\\\]|[^\"\\\\])*'\n",
        "    unterm_comment = r'/\\*.*'\n",
        "\n",
        "    L_HACK = r'<<<'\n",
        "    R_HACK = r'>>>'\n",
        "\n",
        "    LE = r'<='\n",
        "    GE = r'>='\n",
        "    EQ = r'=='\n",
        "    NEQ = r'!='\n",
        "    AND = r'&&'\n",
        "    OR = r'\\|\\|'\n",
        "    CHUCK = r'=>'\n",
        "\n",
        "    LT = r'<'\n",
        "    GT = r'>'\n",
        "    PLUS = r'\\+'\n",
        "    MINUS = r'-'\n",
        "    TIMES = r'\\*'\n",
        "    DIVIDE = r'/'\n",
        "    PERCENT = r'%'\n",
        "    EXCLAMATION = r'!'\n",
        "\n",
        "    LPAREN = r'\\('\n",
        "    RPAREN = r'\\)'\n",
        "    LBRACE = r'\\{'\n",
        "    RBRACE = r'\\}'\n",
        "    COMMA = r','\n",
        "    SEMI = r';'\n",
        "\n",
        "    # Special cases\n",
        "    def ID(self, t):\n",
        "      t.type = self.keywords.get(t.value, \"ID\")\n",
        "      return t\n",
        "\n",
        "    # Define a rule so we can track line numbers\n",
        "    def ignore_newline(self, t):\n",
        "        self.lineno += len(t.value)\n",
        "\n",
        "    def ignore_comment(self, t):\n",
        "        self.lineno += t.value.count(\"\\n\")\n",
        "\n",
        "    def find_column(self, token):\n",
        "        \"\"\"Find the column of the token in its line.\"\"\"\n",
        "        last_cr = self.text.rfind('\\n', 0, token.index)\n",
        "        return token.index - last_cr\n",
        "\n",
        "    # Internal auxiliary methods\n",
        "    def _error(self, msg, token):\n",
        "        location = self._make_location(token)\n",
        "        self.error_func(msg, location[0], location[1])\n",
        "        self.index += 1\n",
        "\n",
        "    def _make_location(self, token):\n",
        "        return token.lineno, self.find_column(token)\n",
        "\n",
        "    def unterm_comment(self, t):\n",
        "        msg = \"Unterminated comment\"\n",
        "        self._error(msg, t)\n",
        "\n",
        "    def unterm_string(self, t):\n",
        "        msg = \"Unterminated string literal\"\n",
        "        self._error(msg, t)\n",
        "\n",
        "    def error(self, t):\n",
        "        msg = \"Illegal character %s\" % repr(t.value[0])\n",
        "        self._error(msg, t)\n",
        "\n",
        "    # Scanner (used only for test)\n",
        "    def scan(self, text):\n",
        "        output = \"\"\n",
        "        for tok in self.tokenize(text):\n",
        "            print(tok)\n",
        "            output += str(tok) + \"\\n\"\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "eeQIg6Oh4-il"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: 1 shift/reduce conflict\n"
          ]
        }
      ],
      "source": [
        "class UChuckParser(Parser):\n",
        "    \"\"\"A parser for the uChuck language.\"\"\"\n",
        "    \n",
        "    # Get the token list from the lexer (required)\n",
        "    tokens = UChuckLexer.tokens\n",
        "\n",
        "    precedence = (\n",
        "        ('right', 'CHUCK'),\n",
        "        ('left', 'OR'),\n",
        "        ('left', 'AND'),\n",
        "        ('left', 'EQ', 'NEQ'),\n",
        "        ('left', 'LT', 'LE', 'GT', 'GE'),\n",
        "        ('left', 'PLUS', 'MINUS'),\n",
        "        ('left', 'TIMES', 'DIVIDE', 'PERCENT'),\n",
        "        ('right', 'EXCLAMATION'),\n",
        "        ('right', 'UMINUS'),  # This is a virtual token for unary minus\n",
        "    )\n",
        "\n",
        "    def __init__(self, error_func=lambda msg, x, y: print(\"Lexical error: %s at %d:%d\" % (msg, x, y), file=sys.stdout)):\n",
        "        self.lexer = UChuckLexer(error_func)\n",
        "\n",
        "    def parse(self, text, lineno=1, index=0):\n",
        "        return super().parse(self.lexer.tokenize(text, lineno, index))\n",
        "\n",
        "    def _token_coord(self, p):\n",
        "        return p.lineno, self.lexer.find_column(p)\n",
        "\n",
        "    def error(self, p):\n",
        "        if p:\n",
        "            if hasattr(p, 'lineno'):\n",
        "                print(\"Error at line %d near the symbol %s \" % (p.lineno, p.value))\n",
        "            else:\n",
        "                print(\"Error near the symbol %s\" % p.value)\n",
        "        else:\n",
        "            print(\"Error at the end of input\")\n",
        "\n",
        "    # <program> ::= <statement_list> EOF\n",
        "    @_('statement_list')\n",
        "    def program(self, p):\n",
        "        return ('program', p.statement_list)\n",
        "\n",
        "    # <statement_list> ::= { <statement> }+\n",
        "    @_('statement statement_list')\n",
        "    def statement_list(self, p):\n",
        "        return [p.statement] + p.statement_list\n",
        "    \n",
        "    @_('statement')\n",
        "    def statement_list(self, p):\n",
        "        return [p.statement]\n",
        "\n",
        "    # <statement> ::= <expression_statement>\n",
        "    #               | <loop_statement>\n",
        "    #               | <selection_statement>\n",
        "    #               | <jump_statement>\n",
        "    #               | <code_segment>\n",
        "    @_('expression_statement',\n",
        "       'loop_statement',\n",
        "       'selection_statement',\n",
        "       'jump_statement',\n",
        "       'code_segment')\n",
        "    def statement(self, p):\n",
        "        return p[0]\n",
        "\n",
        "    # <jump_statement> ::= \"break\" \";\"\n",
        "    #                    | \"continue\" \";\"\n",
        "    @_('BREAK SEMI')\n",
        "    def jump_statement(self, p):\n",
        "        return 'break @ %d:%d' % self._token_coord(p)\n",
        "    \n",
        "    @_('CONTINUE SEMI')\n",
        "    def jump_statement(self, p):\n",
        "        return 'continue @ %d:%d' % self._token_coord(p)\n",
        "\n",
        "    # <selection_statement> ::= \"if\" \"(\" <expression> \")\" <statement> { \"else\" <statement> }?\n",
        "    @_('IF LPAREN expression RPAREN statement ELSE statement')\n",
        "    def selection_statement(self, p):\n",
        "        return ('if @ %d:%d' % self._token_coord(p), p.expression, p.statement0, p.statement1)\n",
        "    \n",
        "    @_('IF LPAREN expression RPAREN statement')\n",
        "    def selection_statement(self, p):\n",
        "        return ('if @ %d:%d' % self._token_coord(p), p.expression, p.statement, None)\n",
        "\n",
        "    # <loop_statement> ::= \"while\" \"(\" <expression> \")\" <statement>\n",
        "    @_('WHILE LPAREN expression RPAREN statement')\n",
        "    def loop_statement(self, p):\n",
        "        return ('while @ %d:%d' % self._token_coord(p), p.expression, p.statement)\n",
        "\n",
        "    # <code_segment> ::= \"{\" { <statement_list> }? \"}\"\n",
        "    @_('LBRACE statement_list RBRACE')\n",
        "    def code_segment(self, p):\n",
        "        return ('stmt_list @ %d:%d' % self._token_coord(p), p.statement_list)\n",
        "    \n",
        "    @_('LBRACE RBRACE')\n",
        "    def code_segment(self, p):\n",
        "        return ('stmt_list @ %d:%d' % self._token_coord(p), [])\n",
        "\n",
        "    # <expression_statement> ::= { <expression> }? \";\"\n",
        "    @_('expression SEMI')\n",
        "    def expression_statement(self, p):\n",
        "        return ('expr', p.expression)\n",
        "    \n",
        "    @_('SEMI')\n",
        "    def expression_statement(self, p):\n",
        "        return ('expr', None)\n",
        "\n",
        "    # <expression> ::= <chuck_expression> { \",\" <chuck_expression> }*\n",
        "    @_('chuck_expression COMMA expression')\n",
        "    def expression(self, p):\n",
        "        if isinstance(p.expression, tuple) and p.expression[0] == 'expr_list':\n",
        "            return ('expr_list', [p.chuck_expression] + p.expression[1])\n",
        "        else:\n",
        "            return ('expr_list', [p.chuck_expression, p.expression])\n",
        "    \n",
        "    @_('chuck_expression')\n",
        "    def expression(self, p):\n",
        "        return p.chuck_expression\n",
        "\n",
        "    # <chuck_expression> ::= { <chuck_expression> \"=>\" }? <decl_expression>\n",
        "    @_('chuck_expression CHUCK decl_expression')\n",
        "    def chuck_expression(self, p):\n",
        "        return ('chuck_op @ %d:%d' % self._token_coord(p), p.decl_expression, p.chuck_expression)\n",
        "    \n",
        "    @_('decl_expression')\n",
        "    def chuck_expression(self, p):\n",
        "        return p.decl_expression\n",
        "\n",
        "    # <decl_expression> ::= <binary_expression>\n",
        "    #                     | <type_decl> <identifier>\n",
        "    @_('binary_expression')\n",
        "    def decl_expression(self, p):\n",
        "        return p.binary_expression\n",
        "    \n",
        "    @_('type_decl identifier')\n",
        "    def decl_expression(self, p):\n",
        "        return ('var_decl', *p.type_decl, *p.identifier)\n",
        "\n",
        "    # <type_decl> ::= \"int\"\n",
        "    #               | \"float\"\n",
        "    #               | <identifier>\n",
        "    @_('INT')\n",
        "    def type_decl(self, p):\n",
        "        return ('type: int @ %d:%d' % self._token_coord(p),)\n",
        "    \n",
        "    @_('FLOAT')\n",
        "    def type_decl(self, p):\n",
        "        return ('type: float @ %d:%d' % self._token_coord(p),)\n",
        "\n",
        "    @_('identifier')\n",
        "    def type_decl(self, p):\n",
        "        return ('type: %s @ %d:%d' % (p.identifier[0].split()[1], *self._token_coord(p)),)\n",
        "\n",
        "    # <binary_expression> ::= <unary_expression>\n",
        "    #                       | <binary_expression> \"+\"  <binary_expression>\n",
        "    #                       | <binary_expression> \"-\"  <binary_expression>\n",
        "    #                       | <binary_expression> \"*\"  <binary_expression>\n",
        "    #                       | <binary_expression> \"/\"  <binary_expression>\n",
        "    #                       | <binary_expression> \"%\"  <binary_expression>\n",
        "    #                       | <binary_expression> \"<=\" <binary_expression>\n",
        "    #                       | <binary_expression> \"<\"  <binary_expression>\n",
        "    #                       | <binary_expression> \">=\" <binary_expression>\n",
        "    #                       | <binary_expression> \">\"  <binary_expression>\n",
        "    #                       | <binary_expression> \"==\" <binary_expression>\n",
        "    #                       | <binary_expression> \"!=\" <binary_expression>\n",
        "    #                       | <binary_expression> \"&&\" <binary_expression>\n",
        "    #                       | <binary_expression> \"||\" <binary_expression>\n",
        "    @_('binary_expression PLUS binary_expression',\n",
        "       'binary_expression MINUS binary_expression',\n",
        "       'binary_expression TIMES binary_expression',\n",
        "       'binary_expression DIVIDE binary_expression',\n",
        "       'binary_expression PERCENT binary_expression',\n",
        "       'binary_expression LE binary_expression',\n",
        "       'binary_expression LT binary_expression',\n",
        "       'binary_expression GE binary_expression',\n",
        "       'binary_expression GT binary_expression',\n",
        "       'binary_expression EQ binary_expression',\n",
        "       'binary_expression NEQ binary_expression',\n",
        "       'binary_expression AND binary_expression',\n",
        "       'binary_expression OR binary_expression')\n",
        "    def binary_expression(self, p):\n",
        "        return ('binary_op: %s @ %d:%d' % (p[1], *self._token_coord(p)), p.binary_expression0, p.binary_expression1)\n",
        "    \n",
        "    @_('unary_expression')\n",
        "    def binary_expression(self, p):\n",
        "        return p.unary_expression\n",
        "\n",
        "    # <unary_expression> ::= <primary_expression>\n",
        "    #                      | <unary_operator> <unary_expression>\n",
        "    @_('unary_operator unary_expression')\n",
        "    def unary_expression(self, p):\n",
        "        return ('unary_op: %s @ %d:%d' % (p.unary_operator[0], *self._token_coord(p)), p.unary_expression)\n",
        "    \n",
        "    @_('MINUS unary_expression %prec UMINUS')\n",
        "    def unary_expression(self, p):\n",
        "        return ('unary_op: - @ %d:%d' % self._token_coord(p), p.unary_expression)\n",
        "    \n",
        "    @_('primary_expression')\n",
        "    def unary_expression(self, p):\n",
        "        return p.primary_expression\n",
        "\n",
        "    # <unary_operator> ::= \"+\"\n",
        "    #                    | \"!\"\n",
        "    @_('PLUS')\n",
        "    def unary_operator(self, p):\n",
        "        return ('+ @ %d:%d' % self._token_coord(p),)\n",
        "    \n",
        "    @_('EXCLAMATION')\n",
        "    def unary_operator(self, p):\n",
        "        return ('! @ %d:%d' % self._token_coord(p),)\n",
        "\n",
        "    # <primary_expression> ::= <literal>\n",
        "    #                        | <location>\n",
        "    #                        | \"<<<\" <expression> \">>>\"\n",
        "    #                        | \"(\" <expression> \")\"\n",
        "    @_('literal')\n",
        "    def primary_expression(self, p):\n",
        "        return p.literal\n",
        "    \n",
        "    @_('location')\n",
        "    def primary_expression(self, p):\n",
        "        return p.location\n",
        "    \n",
        "    @_('L_HACK expression R_HACK')\n",
        "    def primary_expression(self, p):\n",
        "        return ('print @ %d:%d' % self._token_coord(p), p.expression)\n",
        "    \n",
        "    @_('LPAREN expression RPAREN')\n",
        "    def primary_expression(self, p):\n",
        "        return p.expression\n",
        "\n",
        "    @_('INT_VAL')\n",
        "    def literal(self, p):\n",
        "        return 'literal: int, %s @ %d:%d' % (p.INT_VAL, *self._token_coord(p))\n",
        "    \n",
        "    @_('FLOAT_VAL')\n",
        "    def literal(self, p):\n",
        "        return 'literal: float, %s @ %d:%d' % (p.FLOAT_VAL, *self._token_coord(p))\n",
        "    \n",
        "    @_('STRING_LIT')\n",
        "    def literal(self, p):\n",
        "        return 'literal: string, %s @ %d:%d' % (p.STRING_LIT, *self._token_coord(p))\n",
        "    \n",
        "    @_('TRUE')\n",
        "    def literal(self, p):\n",
        "        return 'literal: int, 1 @ %d:%d' % self._token_coord(p)\n",
        "    \n",
        "    @_('FALSE')\n",
        "    def literal(self, p):\n",
        "        return 'literal: int, 0 @ %d:%d' % self._token_coord(p)\n",
        "\n",
        "    # <location> ::= <identifier>\n",
        "    @_('identifier')\n",
        "    def location(self, p):\n",
        "        id_text = p.identifier[0]\n",
        "        parts = id_text.split()\n",
        "        name = parts[1]\n",
        "        coord = ' '.join(parts[3:])\n",
        "        return 'location: %s @ %s' % (name, coord)\n",
        "\n",
        "    # <identifier> ::= ID\n",
        "    @_('ID')\n",
        "    def identifier(self, p):\n",
        "        return ('id: %s @ %d:%d' % (p.ID, *self._token_coord(p)),)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "4VQ3Dq1o645z"
      },
      "outputs": [],
      "source": [
        "def build_tree(root):\n",
        "    return '\\n'.join(_build_tree(root))\n",
        "\n",
        "def _build_tree(node):\n",
        "    if isinstance(node, list):\n",
        "        if not node: return\n",
        "        node = tuple(node)\n",
        "\n",
        "    if not isinstance(node, tuple):\n",
        "        yield \" \"+str(node)\n",
        "        return\n",
        "\n",
        "    values = [_build_tree(n) for n in node]\n",
        "    if len(values) == 1:\n",
        "        yield from build_lines('──', '  ', values[0])\n",
        "        return\n",
        "\n",
        "    start, *mid, end = values\n",
        "    yield from build_lines('┬─', '│ ', start)\n",
        "    for value in mid:\n",
        "        yield from build_lines('├─', '│ ', value)\n",
        "    yield from build_lines('└─', '  ', end)\n",
        "\n",
        "def build_lines(first, other, values):\n",
        "    try:\n",
        "        yield first + next(values)\n",
        "        for value in values:\n",
        "            yield other + value\n",
        "    except StopIteration:\n",
        "        return\n",
        "\n",
        "def print_error(msg, x, y):\n",
        "    # use stdout to match with the output in the .out test files\n",
        "    print(\"Lexical error: %s at %d:%d\" % (msg, x, y), file=sys.stdout)\n",
        "\n",
        "def main(args):\n",
        "    parser = UChuckParser(print_error)\n",
        "    with open(args[0], 'r') if len(args) > 0 else sys.stdin as f:\n",
        "        st = parser.parse(f.read())\n",
        "        if st is not None:\n",
        "            print(build_tree(st))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OA3pL8us7MHW"
      },
      "source": [
        "## Teste\n",
        "Para o desenvolvimento inicial, tente executar o analisador sintático em um arquivo de entrada de exemplo, como:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GkbhtKYY7PiH"
      },
      "source": [
        "```\n",
        "/* print values of factorials */\n",
        "1 => int n;\n",
        "1 => int value;\n",
        "\n",
        "while( n < 10 )\n",
        "{\n",
        "\tvalue * n => value;\n",
        "\t<<< value >>>;\n",
        "\tn + 1 => n;\n",
        "}\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "SjQ31oN_8Fjv"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing test.uck\n"
          ]
        }
      ],
      "source": [
        "%%file test.uck\n",
        "/* print values of factorials */\n",
        "1 => int n;\n",
        "1 => int value;\n",
        "\n",
        "while( n < 10 )\n",
        "{\n",
        "\tvalue * n => value;\n",
        "\t<<< value >>>;\n",
        "\tn + 1 => n;\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXuPOq8b8Hmu"
      },
      "source": [
        "E o resultado será semelhante ao texto mostrado abaixo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfnZU77l8NBA"
      },
      "source": [
        "```\n",
        "┬─ program\n",
        "└─┬─┬─ expr\n",
        "  │ └─┬─ chuck_op @ 2:1\n",
        "  │   ├─┬─ var_decl\n",
        "  │   │ ├─ type: int @ 2:6\n",
        "  │   │ └─ id: n @ 2:10\n",
        "  │   └─ literal: int, 1 @ 2:1\n",
        "  ├─┬─ expr\n",
        "  │ └─┬─ chuck_op @ 3:1\n",
        "  │   ├─┬─ var_decl\n",
        "  │   │ ├─ type: int @ 3:6\n",
        "  │   │ └─ id: value @ 3:10\n",
        "  │   └─ literal: int, 1 @ 3:1\n",
        "  └─┬─ while @ 5:1\n",
        "    ├─┬─ binary_op: < @ 5:8\n",
        "    │ ├─ location: n @ 5:8\n",
        "    │ └─ literal: int, 10 @ 5:12\n",
        "    └─┬─ stmt_list @ 6:1\n",
        "      └─┬─┬─ expr\n",
        "        │ └─┬─ chuck_op @ 7:2\n",
        "        │   ├─ location: value @ 7:15\n",
        "        │   └─┬─ binary_op: * @ 7:2\n",
        "        │     ├─ location: value @ 7:2\n",
        "        │     └─ location: n @ 7:10\n",
        "        ├─┬─ expr\n",
        "        │ └─┬─ print @ 8:2\n",
        "        │   └─ location: value @ 8:6\n",
        "        └─┬─ expr\n",
        "          └─┬─ chuck_op @ 9:2\n",
        "            ├─ location: n @ 9:11\n",
        "            └─┬─ binary_op: + @ 9:2\n",
        "              ├─ location: n @ 9:2\n",
        "              └─ literal: int, 1 @ 9:6\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "XhXsRyrz8mVP"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "┬─ program\n",
            "└─┬─┬─ expr\n",
            "  │ └─┬─ chuck_op @ 2:1\n",
            "  │   ├─┬─ var_decl\n",
            "  │   │ ├─ type: int @ 2:6\n",
            "  │   │ └─ id: n @ 2:10\n",
            "  │   └─ literal: int, 1 @ 2:1\n",
            "  ├─┬─ expr\n",
            "  │ └─┬─ chuck_op @ 3:1\n",
            "  │   ├─┬─ var_decl\n",
            "  │   │ ├─ type: int @ 3:6\n",
            "  │   │ └─ id: value @ 3:10\n",
            "  │   └─ literal: int, 1 @ 3:1\n",
            "  └─┬─ while @ 5:1\n",
            "    ├─┬─ binary_op: < @ 5:8\n",
            "    │ ├─ location: n @ 5:8\n",
            "    │ └─ literal: int, 10 @ 5:12\n",
            "    └─┬─ stmt_list @ 6:1\n",
            "      └─┬─┬─ expr\n",
            "        │ └─┬─ chuck_op @ 7:2\n",
            "        │   ├─ location: value @ 7:15\n",
            "        │   └─┬─ binary_op: * @ 7:2\n",
            "        │     ├─ location: value @ 7:2\n",
            "        │     └─ location: n @ 7:10\n",
            "        ├─┬─ expr\n",
            "        │ └─┬─ print @ 8:2\n",
            "        │   └─ location: value @ 8:6\n",
            "        └─┬─ expr\n",
            "          └─┬─ chuck_op @ 9:2\n",
            "            ├─ location: n @ 9:11\n",
            "            └─┬─ binary_op: + @ 9:2\n",
            "              ├─ location: n @ 9:2\n",
            "              └─ literal: int, 1 @ 9:6\n"
          ]
        }
      ],
      "source": [
        "main([\"test.uck\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4gDZoFKZBQn"
      },
      "source": [
        "## Anexo\n",
        "A lista abaixo define os nós da árvore de sintaxe que devem ser retornados em cada regra da gramática:\n",
        "\n",
        "```\n",
        "program = tuple('program', statement_list)\n",
        "\n",
        "statement_list = list(statement)\n",
        "\n",
        "statement = expression_statement\n",
        "          | loop_statement\n",
        "          | selection_statement\n",
        "          | jump_statement\n",
        "          | code_segment\n",
        "\n",
        "jump_statement = tuple('break @ lineno:column')\n",
        "               | tuple('continue @ lineno:column')\n",
        "\n",
        "selection_statement = tuple('if @ lineno:column', expression, statement0, statement1)\n",
        "\n",
        "loop_statement = tuple('while @ lineno:column', expression, statement)\n",
        "\n",
        "code_segment = tuple('stmt_list @ lineno:column', statement_list)\n",
        "\n",
        "expression_statement = tuple('expr', expression)\n",
        "\n",
        "expression = chuck_expression\n",
        "           | tuple('expr_list', list(chuck_expression))\n",
        "\n",
        "chuck_expression = tuple('chuck_op @ lineno:column', decl_expression, chuck_expression)\n",
        "                 | decl_expression\n",
        "\n",
        "decl_expression = binary_expression\n",
        "                | tuple('var_decl', type_decl, tuple('id: ' + str(ID) + ' @ lineno:column'))\n",
        "\n",
        "type_decl = tuple('type: int @ lineno:column')\n",
        "          | tuple('type: float @ lineno:column')\n",
        "          | tuple('type: ' + str(ID) + ' @ lineno:column')\n",
        "\n",
        "binary_expression = unary_expression\n",
        "                  | tuple('binary_op: + @ lineno:column', binary_expression0, binary_expression1)\n",
        "                  | tuple('binary_op: - @ lineno:column', binary_expression0, binary_expression1)\n",
        "                  | tuple('binary_op: * @ lineno:column', binary_expression0, binary_expression1)\n",
        "                  | tuple('binary_op: / @ lineno:column', binary_expression0, binary_expression1)\n",
        "                  | tuple('binary_op: % @ lineno:column', binary_expression0, binary_expression1)\n",
        "                  | tuple('binary_op: <= @ lineno:column', binary_expression0, binary_expression1)\n",
        "                  | tuple('binary_op: < @ lineno:column', binary_expression0, binary_expression1)\n",
        "                  | tuple('binary_op: >= @ lineno:column', binary_expression0, binary_expression1)\n",
        "                  | tuple('binary_op: > @ lineno:column', binary_expression0, binary_expression1)\n",
        "                  | tuple('binary_op: == @ lineno:column', binary_expression0, binary_expression1)\n",
        "                  | tuple('binary_op: != @ lineno:column', binary_expression0, binary_expression1)\n",
        "                  | tuple('binary_op: && @ lineno:column', binary_expression0, binary_expression1)\n",
        "                  | tuple('binary_op: || @ lineno:column', binary_expression0, binary_expression1)\n",
        "\n",
        "unary_expression = primary_expression\n",
        "                 | tuple('unary_op: ' + str(unary_operator), unary_expression)\n",
        "\n",
        "unary_operator = tuple('+ @ lineno:column')\n",
        "               | tuple('- @ lineno:column')\n",
        "               | tuple('! @ lineno:column')\n",
        "\n",
        "primary_expression = literal\n",
        "                   | location\n",
        "                   | tuple('print @ lineno:column', expression)\n",
        "                   | expression\n",
        "\n",
        "literal = tuple('literal: int, ' + str(INT_VAL) + ' @ lineno:column')\n",
        "        | tuple('literal: float, ' + str(FLOAT_VAL) + ' @ lineno:column')\n",
        "        | tuple('literal: string, ' + str(STRING_LIT) + ' @ lineno:column')\n",
        "        | tuple('literal: int, 1 @ lineno:column')\n",
        "        | tuple('literal: int, 0 @ lineno:column')\n",
        "\n",
        "location = tuple('location: ' + str(ID) + ' @ lineno:column')\n",
        "```\n",
        "\n",
        "Um novo nó é criado sempre que o valor retornado for uma tupla do Python, por exemplo:\n",
        "\n",
        "```python\n",
        "    # <program> ::= <statement_list> EOF\n",
        "    @_('statement_list')\n",
        "    def program(self, p):\n",
        "        return ('program', p.statement_list)\n",
        "```\n",
        "\n",
        "Uma lista de nós é criada sempre que o valor retornado for uma lista do Python, por exemplo:\n",
        "\n",
        "```python\n",
        "    # <statement_list> ::= { <statement> }+\n",
        "    @_('statement { statement }')\n",
        "    def statement_list(self, p):\n",
        "        return [p.statement0] + p.statement1\n",
        "```\n",
        "\n",
        "Uma referência para um nó é criada sempre que o valor retornado em uma regra for o nome de outra regra.\n",
        "\n",
        "Os valores indicados como `lineno` e `column` referem-se aos números de linha e coluna, respectivamente, do símbolo terminal mais à esquerda de cada produção, se houver."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
